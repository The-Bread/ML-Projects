{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "all_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI_RADS</th>\n",
       "      <th>age</th>\n",
       "      <th>shape</th>\n",
       "      <th>margin</th>\n",
       "      <th>density</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>956</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>957</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>958</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>959</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>961 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    BI_RADS age shape margin density  severity\n",
       "0         5  67     3      5       3         1\n",
       "1         4  43     1      1       ?         1\n",
       "2         5  58     4      5       3         1\n",
       "3         4  28     1      1       3         0\n",
       "4         5  74     1      5       ?         1\n",
       "..      ...  ..   ...    ...     ...       ...\n",
       "956       4  47     2      1       3         0\n",
       "957       4  56     4      5       3         1\n",
       "958       4  64     4      5       3         0\n",
       "959       5  66     4      5       3         1\n",
       "960       4  62     3      3       3         0\n",
       "\n",
       "[961 rows x 6 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"mammographic_masses.data.txt\", header=None)\n",
    "df.columns=[\"BI_RADS\", \"age\", \"shape\", \"margin\", \"density\", \"severity\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI_RADS</th>\n",
       "      <th>age</th>\n",
       "      <th>shape</th>\n",
       "      <th>margin</th>\n",
       "      <th>density</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>956</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>957</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>958</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>959</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>961 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    BI_RADS age shape margin density  severity\n",
       "0         5  67     3      5       3         1\n",
       "1         4  43     1      1     NaN         1\n",
       "2         5  58     4      5       3         1\n",
       "3         4  28     1      1       3         0\n",
       "4         5  74     1      5     NaN         1\n",
       "..      ...  ..   ...    ...     ...       ...\n",
       "956       4  47     2      1       3         0\n",
       "957       4  56     4      5       3         1\n",
       "958       4  64     4      5       3         0\n",
       "959       5  66     4      5       3         1\n",
       "960       4  62     3      3       3         0\n",
       "\n",
       "[961 rows x 6 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.replace(\"?\", np.nan)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI_RADS</th>\n",
       "      <th>age</th>\n",
       "      <th>shape</th>\n",
       "      <th>margin</th>\n",
       "      <th>density</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>691</td>\n",
       "      <td>4</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>723</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>745</td>\n",
       "      <td>6</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>752</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>819</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    BI_RADS age shape margin density  severity\n",
       "1         4  43     1      1     NaN         1\n",
       "4         5  74     1      5     NaN         1\n",
       "5         4  65     1    NaN       3         0\n",
       "6         4  70   NaN    NaN       3         0\n",
       "7         5  42     1    NaN       3         0\n",
       "..      ...  ..   ...    ...     ...       ...\n",
       "691       4  72     3    NaN       3         0\n",
       "723       4  60     3    NaN       4         0\n",
       "745       6  76     3    NaN       3         0\n",
       "752       5  48   NaN      4     NaN         1\n",
       "819       4  35     3    NaN       2         0\n",
       "\n",
       "[108 rows x 6 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = df['density'].isnull() | df['margin'].isnull() | df['density'].isnull() | df['severity'].isnull()\n",
    "dl = df[params]\n",
    "dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI_RADS</th>\n",
       "      <th>age</th>\n",
       "      <th>shape</th>\n",
       "      <th>margin</th>\n",
       "      <th>density</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>4.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>826</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>827</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>828</td>\n",
       "      <td>5.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>829</td>\n",
       "      <td>4.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>830 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BI_RADS   age  shape  margin  density  severity\n",
       "0        5.0  67.0    3.0     5.0      3.0       1.0\n",
       "1        5.0  58.0    4.0     5.0      3.0       1.0\n",
       "2        4.0  28.0    1.0     1.0      3.0       0.0\n",
       "3        5.0  57.0    1.0     5.0      3.0       1.0\n",
       "4        5.0  76.0    1.0     4.0      3.0       1.0\n",
       "..       ...   ...    ...     ...      ...       ...\n",
       "825      4.0  47.0    2.0     1.0      3.0       0.0\n",
       "826      4.0  56.0    4.0     5.0      3.0       1.0\n",
       "827      4.0  64.0    4.0     5.0      3.0       0.0\n",
       "828      5.0  66.0    4.0     5.0      3.0       1.0\n",
       "829      4.0  62.0    3.0     3.0      3.0       0.0\n",
       "\n",
       "[830 rows x 6 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna().astype(np.float)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df[[\"age\", \"shape\", \"margin\", \"density\"]])\n",
    "y = np.array(df['severity'])\n",
    "labels = ['positive', 'negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7650629 ,  0.17563638,  1.39618483,  0.24046607],\n",
       "       [ 0.15127063,  0.98104077,  1.39618483,  0.24046607],\n",
       "       [-1.89470363, -1.43517241, -1.157718  ,  0.24046607],\n",
       "       ...,\n",
       "       [ 0.56046548,  0.98104077,  1.39618483,  0.24046607],\n",
       "       [ 0.69686376,  0.98104077,  1.39618483,  0.24046607],\n",
       "       [ 0.42406719,  0.17563638,  0.11923341,  0.24046607]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7836538461538461"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(trainX, trainY)\n",
    "clf.score(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvocationException",
     "evalue": "GraphViz's executables not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-8b8a3e572b6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"age\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"margin\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"density\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mR:\\Work\\Anaconda\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, prog)\u001b[0m\n\u001b[0;32m   1795\u001b[0m             self.__setattr__(\n\u001b[0;32m   1796\u001b[0m                 \u001b[1;34m'create_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfrmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1797\u001b[1;33m                 \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1798\u001b[0m             )\n\u001b[0;32m   1799\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'create_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfrmt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mR:\\Work\\Anaconda\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   1958\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1959\u001b[0m                 raise InvocationException(\n\u001b[1;32m-> 1960\u001b[1;33m                     'GraphViz\\'s executables not found')\n\u001b[0m\u001b[0;32m   1961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1962\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprog\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvocationException\u001b[0m: GraphViz's executables not found"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn import tree\n",
    "import pydotplus\n",
    "\n",
    "dot = tree.export_graphviz(clf, out_file=None, feature_names=[\"age\", \"shape\", \"margin\", \"density\"])\n",
    "graph = pydotplus.graph_from_dot_data(dot)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7421469851531561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.71428571, 0.78571429, 0.76190476, 0.73493976, 0.77108434,\n",
       "       0.68674699, 0.72289157, 0.76829268, 0.76829268, 0.70731707])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=10)\n",
    "print(scores.mean())\n",
    "all_scores.append([\"tree\", scores.mean()])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7588850174216029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.72619048, 0.80952381, 0.82142857, 0.74698795, 0.79518072,\n",
       "       0.6746988 , 0.78313253, 0.75609756, 0.80487805, 0.67073171])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10, class_weight='balanced')\n",
    "scores = cross_val_score(clf, X, y, cv=10)\n",
    "all_scores.append([\"forest\", scores.mean()])\n",
    "print(scores.mean())\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7964988875362076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.71428571, 0.77380952, 0.86904762, 0.80722892, 0.84337349,\n",
       "       0.69879518, 0.80722892, 0.80487805, 0.90243902, 0.74390244])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(kernel=\"linear\")\n",
    "scores = cross_val_score(clf, X, y, cv=10)\n",
    "all_scores.append([\"svm\", scores.mean()])\n",
    "print(scores.mean())\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7854795488574507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.77380952, 0.76190476, 0.83333333, 0.74698795, 0.87951807,\n",
       "       0.72289157, 0.81927711, 0.79268293, 0.81707317, 0.70731707])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=10)\n",
    "scores = cross_val_score(clf, X, y, cv=10)\n",
    "all_scores.append([\"knn\", scores.mean()])\n",
    "print(scores.mean())\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7239123742356184\n",
      "0.6889838098036746\n",
      "0.7541080699103032\n",
      "0.7300813008130081\n",
      "0.7735464506108056\n",
      "0.7626163189342738\n",
      "0.7940595133145824\n",
      "0.7747082406280172\n",
      "0.7880200243482641\n",
      "0.7854795488574507\n",
      "0.7915333809104012\n",
      "0.7794257168045002\n",
      "0.7819084701174035\n",
      "0.7915039950743742\n",
      "0.7878748443250353\n",
      "0.7794411093852764\n",
      "0.7818073688482151\n",
      "0.775681121699341\n",
      "0.7805147418944068\n",
      "0.7828666582707136\n",
      "0.7853927906748946\n",
      "0.7817342540895289\n",
      "0.7805588206484475\n",
      "0.780587506821712\n",
      "0.7878171221471251\n",
      "0.7866269957880302\n",
      "0.7854365195975539\n",
      "0.7902271105327232\n",
      "0.7865979597833844\n",
      "0.7878314652337574\n",
      "0.7914172368918182\n",
      "0.7878314652337574\n",
      "0.7865976099520032\n",
      "0.7866119530386354\n",
      "0.7866262961252677\n",
      "0.7854358199347914\n",
      "0.7866843681345592\n",
      "0.7866553321299133\n",
      "0.7878891874116676\n",
      "0.7854791990260694\n",
      "0.7854645061080558\n",
      "0.7818500482767305\n",
      "0.7830692106404713\n",
      "0.783054867553839\n",
      "0.783054867553839\n",
      "0.7854648559394373\n",
      "0.7866843681345591\n",
      "0.7890653205155116\n",
      "0.7902995256286471\n",
      "\n",
      "\n",
      " BEST K FOR: 7, 0.7940595133145824\n"
     ]
    }
   ],
   "source": [
    "best_K = [0, 0]\n",
    "\n",
    "for i in range(1, 50):\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors=i)\n",
    "    scores = cross_val_score(clf, X, y, cv=10)\n",
    "    \n",
    "    if scores.mean() > best_K[1]:\n",
    "        best_K = [i, scores.mean()]\n",
    "        \n",
    "    print(scores.mean())\n",
    "    \n",
    "print(f'\\n\\n BEST K FOR: {best_K[0]}, {best_K[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7844055665169388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.73809524, 0.76190476, 0.82142857, 0.8313253 , 0.8313253 ,\n",
       "       0.73493976, 0.74698795, 0.76829268, 0.91463415, 0.69512195])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "clf = MultinomialNB()\n",
    "scalar = MinMaxScaler()\n",
    "minmax_X = scalar.fit_transform(X)\n",
    "scores = cross_val_score(clf, minmax_X, y, cv=10)\n",
    "all_scores.append([\"naive bayes\", scores.mean()])\n",
    "print(scores.mean())\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X[:,0], X[:,1], c=y.astype(np.float))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear         0.7940888991506094\n",
      "poly         0.7988070749898549\n",
      "sigmoid         0.7916502245917467\n",
      "rbf         0.795221303331794\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "kernels = ['linear', 'poly', 'sigmoid', 'rbf']\n",
    "\n",
    "for kernel in kernels:\n",
    "    svc = svm.SVC(kernel=kernel, C=1.0)\n",
    "    scores = cross_val_score(svc, minmax_X, y, cv=10)\n",
    "    all_scores.append([\"svm \" + kernel, scores.mean()])\n",
    "    print(kernel, \"       \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76190476 0.76190476 0.88095238 0.81927711 0.8313253  0.71084337\n",
      " 0.79518072 0.82926829 0.8902439  0.79268293]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8073583532737221"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log = LogisticRegression()\n",
    "scores = cross_val_score(log, X, y, cv=10)\n",
    "all_scores.append([\"linear regression\", scores.mean()])\n",
    "print(scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers as ly\n",
    "\n",
    "# model.fit(trainX, trainY, epochs=50, batch_size=6)\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(ly.Dense(6, activation=\"relu\"))\n",
    "    model.add(ly.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss='binary_crossentropy' , metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 747 samples\n",
      "Epoch 1/100\n",
      "747/747 [==============================] - 0s 328us/sample - loss: 0.7392 - acc: 0.5248\n",
      "Epoch 2/100\n",
      "747/747 [==============================] - 0s 96us/sample - loss: 0.6953 - acc: 0.5676\n",
      "Epoch 3/100\n",
      "747/747 [==============================] - 0s 89us/sample - loss: 0.6596 - acc: 0.5917\n",
      "Epoch 4/100\n",
      "747/747 [==============================] - 0s 62us/sample - loss: 0.6319 - acc: 0.6064\n",
      "Epoch 5/100\n",
      "747/747 [==============================] - 0s 58us/sample - loss: 0.6089 - acc: 0.6238\n",
      "Epoch 6/100\n",
      "747/747 [==============================] - 0s 65us/sample - loss: 0.5905 - acc: 0.6506\n",
      "Epoch 7/100\n",
      "747/747 [==============================] - 0s 71us/sample - loss: 0.5755 - acc: 0.6667\n",
      "Epoch 8/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.5628 - acc: 0.6881\n",
      "Epoch 9/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.5517 - acc: 0.7028\n",
      "Epoch 10/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.5421 - acc: 0.7216\n",
      "Epoch 11/100\n",
      "747/747 [==============================] - 0s 62us/sample - loss: 0.5327 - acc: 0.7376\n",
      "Epoch 12/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.5245 - acc: 0.7537\n",
      "Epoch 13/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.5161 - acc: 0.7644\n",
      "Epoch 14/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.5082 - acc: 0.7724\n",
      "Epoch 15/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.5008 - acc: 0.7805\n",
      "Epoch 16/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4946 - acc: 0.7858\n",
      "Epoch 17/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4883 - acc: 0.7925\n",
      "Epoch 18/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4834 - acc: 0.7965\n",
      "Epoch 19/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4786 - acc: 0.7952\n",
      "Epoch 20/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4740 - acc: 0.7979\n",
      "Epoch 21/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4702 - acc: 0.7992\n",
      "Epoch 22/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4668 - acc: 0.7979\n",
      "Epoch 23/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4636 - acc: 0.7979\n",
      "Epoch 24/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4610 - acc: 0.7979\n",
      "Epoch 25/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4585 - acc: 0.7979\n",
      "Epoch 26/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4564 - acc: 0.7979\n",
      "Epoch 27/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4543 - acc: 0.7992\n",
      "Epoch 28/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4525 - acc: 0.8005\n",
      "Epoch 29/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4509 - acc: 0.8005\n",
      "Epoch 30/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4495 - acc: 0.8019\n",
      "Epoch 31/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4480 - acc: 0.8032\n",
      "Epoch 32/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4466 - acc: 0.8032\n",
      "Epoch 33/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4454 - acc: 0.8032\n",
      "Epoch 34/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4443 - acc: 0.8046\n",
      "Epoch 35/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4431 - acc: 0.8046\n",
      "Epoch 36/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4421 - acc: 0.8059\n",
      "Epoch 37/100\n",
      "747/747 [==============================] - 0s 32us/sample - loss: 0.4411 - acc: 0.8032\n",
      "Epoch 38/100\n",
      "747/747 [==============================] - 0s 35us/sample - loss: 0.4404 - acc: 0.8019\n",
      "Epoch 39/100\n",
      "747/747 [==============================] - 0s 35us/sample - loss: 0.4395 - acc: 0.8019\n",
      "Epoch 40/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4387 - acc: 0.8005\n",
      "Epoch 41/100\n",
      "747/747 [==============================] - 0s 58us/sample - loss: 0.4381 - acc: 0.8032\n",
      "Epoch 42/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4374 - acc: 0.8032\n",
      "Epoch 43/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4366 - acc: 0.8032\n",
      "Epoch 44/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4360 - acc: 0.8046\n",
      "Epoch 45/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4353 - acc: 0.8072\n",
      "Epoch 46/100\n",
      "747/747 [==============================] - 0s 35us/sample - loss: 0.4349 - acc: 0.8072\n",
      "Epoch 47/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4343 - acc: 0.8072\n",
      "Epoch 48/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4338 - acc: 0.8072\n",
      "Epoch 49/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4335 - acc: 0.8059\n",
      "Epoch 50/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4330 - acc: 0.8059\n",
      "Epoch 51/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4327 - acc: 0.8059\n",
      "Epoch 52/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4323 - acc: 0.8072\n",
      "Epoch 53/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4320 - acc: 0.8072\n",
      "Epoch 54/100\n",
      "747/747 [==============================] - 0s 36us/sample - loss: 0.4316 - acc: 0.8072\n",
      "Epoch 55/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4313 - acc: 0.8086\n",
      "Epoch 56/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4309 - acc: 0.8112\n",
      "Epoch 57/100\n",
      "747/747 [==============================] - 0s 32us/sample - loss: 0.4307 - acc: 0.8099\n",
      "Epoch 58/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4306 - acc: 0.8086\n",
      "Epoch 59/100\n",
      "747/747 [==============================] - 0s 33us/sample - loss: 0.4301 - acc: 0.8086\n",
      "Epoch 60/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4299 - acc: 0.8099\n",
      "Epoch 61/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4296 - acc: 0.8099\n",
      "Epoch 62/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4295 - acc: 0.8099\n",
      "Epoch 63/100\n",
      "747/747 [==============================] - 0s 36us/sample - loss: 0.4291 - acc: 0.8099\n",
      "Epoch 64/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4289 - acc: 0.8099\n",
      "Epoch 65/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4288 - acc: 0.8099\n",
      "Epoch 66/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4285 - acc: 0.8099\n",
      "Epoch 67/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4284 - acc: 0.8099\n",
      "Epoch 68/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4282 - acc: 0.8099\n",
      "Epoch 69/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4279 - acc: 0.8086\n",
      "Epoch 70/100\n",
      "747/747 [==============================] - 0s 34us/sample - loss: 0.4278 - acc: 0.8086\n",
      "Epoch 71/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4279 - acc: 0.8086\n",
      "Epoch 72/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.4275 - acc: 0.8099\n",
      "Epoch 73/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4273 - acc: 0.8099\n",
      "Epoch 74/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4273 - acc: 0.8086\n",
      "Epoch 75/100\n",
      "747/747 [==============================] - ETA: 0s - loss: 0.3530 - acc: 0.843 - 0s 40us/sample - loss: 0.4271 - acc: 0.8099\n",
      "Epoch 76/100\n",
      "747/747 [==============================] - 0s 36us/sample - loss: 0.4270 - acc: 0.8099\n",
      "Epoch 77/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4268 - acc: 0.8086\n",
      "Epoch 78/100\n",
      "747/747 [==============================] - 0s 36us/sample - loss: 0.4268 - acc: 0.8086\n",
      "Epoch 79/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4266 - acc: 0.8086\n",
      "Epoch 80/100\n",
      "747/747 [==============================] - 0s 33us/sample - loss: 0.4264 - acc: 0.8112\n",
      "Epoch 81/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4266 - acc: 0.8112\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4262 - acc: 0.8112\n",
      "Epoch 83/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4263 - acc: 0.8112\n",
      "Epoch 84/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4262 - acc: 0.8112\n",
      "Epoch 85/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4261 - acc: 0.8112\n",
      "Epoch 86/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4260 - acc: 0.8153\n",
      "Epoch 87/100\n",
      "747/747 [==============================] - 0s 63us/sample - loss: 0.4259 - acc: 0.8166\n",
      "Epoch 88/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4258 - acc: 0.8166\n",
      "Epoch 89/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4257 - acc: 0.8166\n",
      "Epoch 90/100\n",
      "747/747 [==============================] - 0s 32us/sample - loss: 0.4257 - acc: 0.8166\n",
      "Epoch 91/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4256 - acc: 0.8166\n",
      "Epoch 92/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4255 - acc: 0.8166\n",
      "Epoch 93/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4255 - acc: 0.8166\n",
      "Epoch 94/100\n",
      "747/747 [==============================] - 0s 64us/sample - loss: 0.4255 - acc: 0.8166\n",
      "Epoch 95/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4253 - acc: 0.8153\n",
      "Epoch 96/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4252 - acc: 0.8153\n",
      "Epoch 97/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4251 - acc: 0.8153\n",
      "Epoch 98/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4250 - acc: 0.8153\n",
      "Epoch 99/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4251 - acc: 0.8153\n",
      "Epoch 100/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4249 - acc: 0.8166\n",
      "83/83 [==============================] - 0s 861us/sample - loss: 0.6238 - acc: 0.7711\n",
      "Train on 747 samples\n",
      "Epoch 1/100\n",
      "747/747 [==============================] - 0s 296us/sample - loss: 0.6567 - acc: 0.6827\n",
      "Epoch 2/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.6245 - acc: 0.7269\n",
      "Epoch 3/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.5976 - acc: 0.7416\n",
      "Epoch 4/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.5740 - acc: 0.7523\n",
      "Epoch 5/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.5537 - acc: 0.7724\n",
      "Epoch 6/100\n",
      "747/747 [==============================] - 0s 35us/sample - loss: 0.5364 - acc: 0.7805\n",
      "Epoch 7/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.5208 - acc: 0.7831\n",
      "Epoch 8/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.5080 - acc: 0.7818\n",
      "Epoch 9/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4971 - acc: 0.7845\n",
      "Epoch 10/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4885 - acc: 0.7858\n",
      "Epoch 11/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4811 - acc: 0.7858\n",
      "Epoch 12/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4757 - acc: 0.7831\n",
      "Epoch 13/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4713 - acc: 0.7858\n",
      "Epoch 14/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4677 - acc: 0.7912\n",
      "Epoch 15/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4646 - acc: 0.7952\n",
      "Epoch 16/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4621 - acc: 0.7952\n",
      "Epoch 17/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4601 - acc: 0.7952\n",
      "Epoch 18/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4583 - acc: 0.7965\n",
      "Epoch 19/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4569 - acc: 0.7965\n",
      "Epoch 20/100\n",
      "747/747 [==============================] - 0s 114us/sample - loss: 0.4556 - acc: 0.7965\n",
      "Epoch 21/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4546 - acc: 0.7965\n",
      "Epoch 22/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4538 - acc: 0.7965\n",
      "Epoch 23/100\n",
      "747/747 [==============================] - 0s 35us/sample - loss: 0.4528 - acc: 0.7979\n",
      "Epoch 24/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4521 - acc: 0.7979\n",
      "Epoch 25/100\n",
      "747/747 [==============================] - 0s 35us/sample - loss: 0.4515 - acc: 0.7979\n",
      "Epoch 26/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4509 - acc: 0.7979\n",
      "Epoch 27/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4506 - acc: 0.7979\n",
      "Epoch 28/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4501 - acc: 0.7992\n",
      "Epoch 29/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4496 - acc: 0.8005\n",
      "Epoch 30/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4492 - acc: 0.8005\n",
      "Epoch 31/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4488 - acc: 0.7992\n",
      "Epoch 32/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4487 - acc: 0.7992\n",
      "Epoch 33/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4483 - acc: 0.7992\n",
      "Epoch 34/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4480 - acc: 0.7992\n",
      "Epoch 35/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4478 - acc: 0.8019\n",
      "Epoch 36/100\n",
      "747/747 [==============================] - 0s 34us/sample - loss: 0.4474 - acc: 0.8005\n",
      "Epoch 37/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4471 - acc: 0.8019\n",
      "Epoch 38/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4469 - acc: 0.8019\n",
      "Epoch 39/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4466 - acc: 0.8005\n",
      "Epoch 40/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4467 - acc: 0.7979\n",
      "Epoch 41/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4465 - acc: 0.7992\n",
      "Epoch 42/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4462 - acc: 0.8005\n",
      "Epoch 43/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4461 - acc: 0.8005\n",
      "Epoch 44/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4457 - acc: 0.8005\n",
      "Epoch 45/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4455 - acc: 0.8005\n",
      "Epoch 46/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4455 - acc: 0.8019\n",
      "Epoch 47/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4452 - acc: 0.8005\n",
      "Epoch 48/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4451 - acc: 0.8005\n",
      "Epoch 49/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4450 - acc: 0.7992\n",
      "Epoch 50/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4449 - acc: 0.7992\n",
      "Epoch 51/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4446 - acc: 0.7992\n",
      "Epoch 52/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4445 - acc: 0.7992\n",
      "Epoch 53/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4445 - acc: 0.8019\n",
      "Epoch 54/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4443 - acc: 0.8019\n",
      "Epoch 55/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4441 - acc: 0.8019\n",
      "Epoch 56/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4437 - acc: 0.8032\n",
      "Epoch 57/100\n",
      "747/747 [==============================] - 0s 35us/sample - loss: 0.4436 - acc: 0.8032\n",
      "Epoch 58/100\n",
      "747/747 [==============================] - 0s 32us/sample - loss: 0.4434 - acc: 0.8032\n",
      "Epoch 59/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4434 - acc: 0.8019\n",
      "Epoch 60/100\n",
      "747/747 [==============================] - ETA: 0s - loss: 0.3601 - acc: 0.812 - 0s 44us/sample - loss: 0.4431 - acc: 0.8019\n",
      "Epoch 61/100\n",
      "747/747 [==============================] - 0s 57us/sample - loss: 0.4431 - acc: 0.8032\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747/747 [==============================] - 0s 35us/sample - loss: 0.4428 - acc: 0.8046\n",
      "Epoch 63/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4427 - acc: 0.8059\n",
      "Epoch 64/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4427 - acc: 0.8032\n",
      "Epoch 65/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4427 - acc: 0.8046\n",
      "Epoch 66/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4424 - acc: 0.8046\n",
      "Epoch 67/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4427 - acc: 0.8059\n",
      "Epoch 68/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4421 - acc: 0.8046\n",
      "Epoch 69/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4420 - acc: 0.8019\n",
      "Epoch 70/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.4421 - acc: 0.8059\n",
      "Epoch 71/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4418 - acc: 0.8059\n",
      "Epoch 72/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4417 - acc: 0.8059\n",
      "Epoch 73/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4416 - acc: 0.8059\n",
      "Epoch 74/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4415 - acc: 0.8059\n",
      "Epoch 75/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4415 - acc: 0.8072\n",
      "Epoch 76/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4414 - acc: 0.8072\n",
      "Epoch 77/100\n",
      "747/747 [==============================] - 0s 54us/sample - loss: 0.4411 - acc: 0.8072\n",
      "Epoch 78/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4411 - acc: 0.8072\n",
      "Epoch 79/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4410 - acc: 0.8059\n",
      "Epoch 80/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4408 - acc: 0.8059\n",
      "Epoch 81/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4410 - acc: 0.8059\n",
      "Epoch 82/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4411 - acc: 0.8046\n",
      "Epoch 83/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4406 - acc: 0.8059\n",
      "Epoch 84/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4406 - acc: 0.8059\n",
      "Epoch 85/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4405 - acc: 0.8059\n",
      "Epoch 86/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4403 - acc: 0.8059\n",
      "Epoch 87/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4405 - acc: 0.8046\n",
      "Epoch 88/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4401 - acc: 0.8046\n",
      "Epoch 89/100\n",
      "747/747 [==============================] - 0s 63us/sample - loss: 0.4400 - acc: 0.8046\n",
      "Epoch 90/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4400 - acc: 0.8059\n",
      "Epoch 91/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4398 - acc: 0.8059\n",
      "Epoch 92/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4397 - acc: 0.8059\n",
      "Epoch 93/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4396 - acc: 0.8072\n",
      "Epoch 94/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4394 - acc: 0.8072\n",
      "Epoch 95/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4394 - acc: 0.8072\n",
      "Epoch 96/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4393 - acc: 0.8072\n",
      "Epoch 97/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4391 - acc: 0.8086\n",
      "Epoch 98/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4392 - acc: 0.8086\n",
      "Epoch 99/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4389 - acc: 0.8086\n",
      "Epoch 100/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4389 - acc: 0.8086\n",
      "83/83 [==============================] - 0s 1ms/sample - loss: 0.4819 - acc: 0.7711\n",
      "Train on 747 samples\n",
      "Epoch 1/100\n",
      "747/747 [==============================] - 0s 271us/sample - loss: 0.7253 - acc: 0.4592\n",
      "Epoch 2/100\n",
      "747/747 [==============================] - 0s 52us/sample - loss: 0.6947 - acc: 0.5248\n",
      "Epoch 3/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.6677 - acc: 0.6145\n",
      "Epoch 4/100\n",
      "747/747 [==============================] - 0s 54us/sample - loss: 0.6433 - acc: 0.6466\n",
      "Epoch 5/100\n",
      "747/747 [==============================] - 0s 53us/sample - loss: 0.6213 - acc: 0.6760\n",
      "Epoch 6/100\n",
      "747/747 [==============================] - 0s 58us/sample - loss: 0.6008 - acc: 0.7349\n",
      "Epoch 7/100\n",
      "747/747 [==============================] - 0s 56us/sample - loss: 0.5816 - acc: 0.7564\n",
      "Epoch 8/100\n",
      "747/747 [==============================] - 0s 52us/sample - loss: 0.5642 - acc: 0.7604\n",
      "Epoch 9/100\n",
      "747/747 [==============================] - 0s 54us/sample - loss: 0.5487 - acc: 0.7644\n",
      "Epoch 10/100\n",
      "747/747 [==============================] - 0s 52us/sample - loss: 0.5344 - acc: 0.7604\n",
      "Epoch 11/100\n",
      "747/747 [==============================] - 0s 86us/sample - loss: 0.5226 - acc: 0.7631\n",
      "Epoch 12/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.5126 - acc: 0.7657\n",
      "Epoch 13/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.5038 - acc: 0.7711\n",
      "Epoch 14/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4961 - acc: 0.7697\n",
      "Epoch 15/100\n",
      "747/747 [==============================] - 0s 34us/sample - loss: 0.4899 - acc: 0.7751\n",
      "Epoch 16/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4847 - acc: 0.7778\n",
      "Epoch 17/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4801 - acc: 0.7805\n",
      "Epoch 18/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4763 - acc: 0.7858\n",
      "Epoch 19/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4732 - acc: 0.7858\n",
      "Epoch 20/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4708 - acc: 0.7858\n",
      "Epoch 21/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4688 - acc: 0.7871\n",
      "Epoch 22/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4672 - acc: 0.7885\n",
      "Epoch 23/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4658 - acc: 0.7912\n",
      "Epoch 24/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4645 - acc: 0.7885\n",
      "Epoch 25/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4636 - acc: 0.7885\n",
      "Epoch 26/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4628 - acc: 0.7898\n",
      "Epoch 27/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4621 - acc: 0.7885\n",
      "Epoch 28/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4615 - acc: 0.7898\n",
      "Epoch 29/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4608 - acc: 0.7898\n",
      "Epoch 30/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4602 - acc: 0.7925\n",
      "Epoch 31/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4598 - acc: 0.7925\n",
      "Epoch 32/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4594 - acc: 0.7925\n",
      "Epoch 33/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4596 - acc: 0.7925\n",
      "Epoch 34/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4587 - acc: 0.7925\n",
      "Epoch 35/100\n",
      "747/747 [==============================] - 0s 34us/sample - loss: 0.4584 - acc: 0.7938\n",
      "Epoch 36/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4581 - acc: 0.7952\n",
      "Epoch 37/100\n",
      "747/747 [==============================] - 0s 36us/sample - loss: 0.4578 - acc: 0.7938\n",
      "Epoch 38/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4575 - acc: 0.7952\n",
      "Epoch 39/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4574 - acc: 0.7979\n",
      "Epoch 40/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4569 - acc: 0.7992\n",
      "Epoch 41/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4568 - acc: 0.7992\n",
      "Epoch 42/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4566 - acc: 0.7979\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747/747 [==============================] - 0s 55us/sample - loss: 0.4562 - acc: 0.7979\n",
      "Epoch 44/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4559 - acc: 0.7979\n",
      "Epoch 45/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4557 - acc: 0.7979\n",
      "Epoch 46/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4556 - acc: 0.7979\n",
      "Epoch 47/100\n",
      "747/747 [==============================] - 0s 54us/sample - loss: 0.4554 - acc: 0.7992\n",
      "Epoch 48/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4552 - acc: 0.7992\n",
      "Epoch 49/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4549 - acc: 0.7992\n",
      "Epoch 50/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4548 - acc: 0.8005\n",
      "Epoch 51/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4546 - acc: 0.8005\n",
      "Epoch 52/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4547 - acc: 0.8005\n",
      "Epoch 53/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4545 - acc: 0.8019\n",
      "Epoch 54/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4541 - acc: 0.8032\n",
      "Epoch 55/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4541 - acc: 0.8019\n",
      "Epoch 56/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.4536 - acc: 0.8019\n",
      "Epoch 57/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4535 - acc: 0.8032\n",
      "Epoch 58/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4533 - acc: 0.8019\n",
      "Epoch 59/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4534 - acc: 0.8005\n",
      "Epoch 60/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4531 - acc: 0.8032\n",
      "Epoch 61/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4530 - acc: 0.8032\n",
      "Epoch 62/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4528 - acc: 0.8019\n",
      "Epoch 63/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4528 - acc: 0.8046\n",
      "Epoch 64/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4526 - acc: 0.8046\n",
      "Epoch 65/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4525 - acc: 0.8032\n",
      "Epoch 66/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4523 - acc: 0.8019\n",
      "Epoch 67/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4522 - acc: 0.8019\n",
      "Epoch 68/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4521 - acc: 0.8032\n",
      "Epoch 69/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4520 - acc: 0.8046\n",
      "Epoch 70/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4519 - acc: 0.8046\n",
      "Epoch 71/100\n",
      "747/747 [==============================] - 0s 53us/sample - loss: 0.4518 - acc: 0.8032\n",
      "Epoch 72/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4516 - acc: 0.8032\n",
      "Epoch 73/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4515 - acc: 0.8059\n",
      "Epoch 74/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4516 - acc: 0.8072\n",
      "Epoch 75/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4514 - acc: 0.8059\n",
      "Epoch 76/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4513 - acc: 0.8072\n",
      "Epoch 77/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4513 - acc: 0.8072\n",
      "Epoch 78/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4512 - acc: 0.8072\n",
      "Epoch 79/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4511 - acc: 0.8072\n",
      "Epoch 80/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4510 - acc: 0.8086\n",
      "Epoch 81/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4511 - acc: 0.8086\n",
      "Epoch 82/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4510 - acc: 0.8099\n",
      "Epoch 83/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4509 - acc: 0.8072\n",
      "Epoch 84/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4508 - acc: 0.8086\n",
      "Epoch 85/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4506 - acc: 0.8086\n",
      "Epoch 86/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4505 - acc: 0.8086\n",
      "Epoch 87/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4505 - acc: 0.8099\n",
      "Epoch 88/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4505 - acc: 0.8086\n",
      "Epoch 89/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4504 - acc: 0.8059\n",
      "Epoch 90/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4505 - acc: 0.8059\n",
      "Epoch 91/100\n",
      "747/747 [==============================] - 0s 36us/sample - loss: 0.4502 - acc: 0.8046\n",
      "Epoch 92/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4502 - acc: 0.8072\n",
      "Epoch 93/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4501 - acc: 0.8072\n",
      "Epoch 94/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4500 - acc: 0.8059\n",
      "Epoch 95/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4500 - acc: 0.8059\n",
      "Epoch 96/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4499 - acc: 0.8059\n",
      "Epoch 97/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4499 - acc: 0.8059\n",
      "Epoch 98/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4499 - acc: 0.8059\n",
      "Epoch 99/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4498 - acc: 0.8059\n",
      "Epoch 100/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4497 - acc: 0.8059\n",
      "83/83 [==============================] - 0s 925us/sample - loss: 0.3616 - acc: 0.8675\n",
      "Train on 747 samples\n",
      "Epoch 1/100\n",
      "747/747 [==============================] - 0s 278us/sample - loss: 0.9645 - acc: 0.4672\n",
      "Epoch 2/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.8948 - acc: 0.5007\n",
      "Epoch 3/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.8346 - acc: 0.5127\n",
      "Epoch 4/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.7826 - acc: 0.5328\n",
      "Epoch 5/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.7353 - acc: 0.5489\n",
      "Epoch 6/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.6949 - acc: 0.5582\n",
      "Epoch 7/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.6586 - acc: 0.5783\n",
      "Epoch 8/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.6270 - acc: 0.6037\n",
      "Epoch 9/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.5993 - acc: 0.6493\n",
      "Epoch 10/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.5757 - acc: 0.6841\n",
      "Epoch 11/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.5553 - acc: 0.7443\n",
      "Epoch 12/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.5381 - acc: 0.7845\n",
      "Epoch 13/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.5234 - acc: 0.8019\n",
      "Epoch 14/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.5104 - acc: 0.8046\n",
      "Epoch 15/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4999 - acc: 0.8099\n",
      "Epoch 16/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4911 - acc: 0.8086\n",
      "Epoch 17/100\n",
      "747/747 [==============================] - 0s 33us/sample - loss: 0.4837 - acc: 0.8072\n",
      "Epoch 18/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4776 - acc: 0.8046\n",
      "Epoch 19/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4728 - acc: 0.8032\n",
      "Epoch 20/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4686 - acc: 0.8032\n",
      "Epoch 21/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4654 - acc: 0.8032\n",
      "Epoch 22/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4624 - acc: 0.8046\n",
      "Epoch 23/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4601 - acc: 0.8046\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4579 - acc: 0.8032\n",
      "Epoch 25/100\n",
      "747/747 [==============================] - ETA: 0s - loss: 0.5081 - acc: 0.750 - 0s 37us/sample - loss: 0.4561 - acc: 0.8032\n",
      "Epoch 26/100\n",
      "747/747 [==============================] - 0s 60us/sample - loss: 0.4547 - acc: 0.8032\n",
      "Epoch 27/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4538 - acc: 0.8019\n",
      "Epoch 28/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4527 - acc: 0.8019\n",
      "Epoch 29/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4520 - acc: 0.8005\n",
      "Epoch 30/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4516 - acc: 0.8005\n",
      "Epoch 31/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4509 - acc: 0.8005\n",
      "Epoch 32/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4504 - acc: 0.8005\n",
      "Epoch 33/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4502 - acc: 0.7992\n",
      "Epoch 34/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4496 - acc: 0.7992\n",
      "Epoch 35/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4496 - acc: 0.8005\n",
      "Epoch 36/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4492 - acc: 0.8005\n",
      "Epoch 37/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4494 - acc: 0.7992\n",
      "Epoch 38/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4488 - acc: 0.7992\n",
      "Epoch 39/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4488 - acc: 0.7992\n",
      "Epoch 40/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4488 - acc: 0.7979\n",
      "Epoch 41/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4483 - acc: 0.8019\n",
      "Epoch 42/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4482 - acc: 0.7992\n",
      "Epoch 43/100\n",
      "747/747 [==============================] - 0s 96us/sample - loss: 0.4480 - acc: 0.8005\n",
      "Epoch 44/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4481 - acc: 0.8005\n",
      "Epoch 45/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4476 - acc: 0.7992\n",
      "Epoch 46/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4476 - acc: 0.8019\n",
      "Epoch 47/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4478 - acc: 0.8019\n",
      "Epoch 48/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4475 - acc: 0.8019\n",
      "Epoch 49/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4474 - acc: 0.8032\n",
      "Epoch 50/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4472 - acc: 0.8032\n",
      "Epoch 51/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4473 - acc: 0.8032\n",
      "Epoch 52/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4471 - acc: 0.8019\n",
      "Epoch 53/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.4470 - acc: 0.8046\n",
      "Epoch 54/100\n",
      "747/747 [==============================] - 0s 54us/sample - loss: 0.4469 - acc: 0.8046\n",
      "Epoch 55/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4468 - acc: 0.8032\n",
      "Epoch 56/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4467 - acc: 0.8032\n",
      "Epoch 57/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4467 - acc: 0.8032\n",
      "Epoch 58/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4465 - acc: 0.8032\n",
      "Epoch 59/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4466 - acc: 0.8032\n",
      "Epoch 60/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4464 - acc: 0.8032\n",
      "Epoch 61/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4463 - acc: 0.8032\n",
      "Epoch 62/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4463 - acc: 0.8032\n",
      "Epoch 63/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4463 - acc: 0.8019\n",
      "Epoch 64/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4461 - acc: 0.8019\n",
      "Epoch 65/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4461 - acc: 0.8032\n",
      "Epoch 66/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4460 - acc: 0.8032\n",
      "Epoch 67/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4458 - acc: 0.8019\n",
      "Epoch 68/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4459 - acc: 0.8032\n",
      "Epoch 69/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4459 - acc: 0.8032\n",
      "Epoch 70/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4457 - acc: 0.8032\n",
      "Epoch 71/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4456 - acc: 0.8032\n",
      "Epoch 72/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4455 - acc: 0.8019\n",
      "Epoch 73/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4455 - acc: 0.8032\n",
      "Epoch 74/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4455 - acc: 0.8032\n",
      "Epoch 75/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4453 - acc: 0.8032\n",
      "Epoch 76/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4452 - acc: 0.8032\n",
      "Epoch 77/100\n",
      "747/747 [==============================] - 0s 36us/sample - loss: 0.4452 - acc: 0.8019\n",
      "Epoch 78/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4453 - acc: 0.8032\n",
      "Epoch 79/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4450 - acc: 0.8032\n",
      "Epoch 80/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4451 - acc: 0.8032\n",
      "Epoch 81/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4453 - acc: 0.8046\n",
      "Epoch 82/100\n",
      "747/747 [==============================] - 0s 35us/sample - loss: 0.4448 - acc: 0.8046\n",
      "Epoch 83/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4449 - acc: 0.8032\n",
      "Epoch 84/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4448 - acc: 0.8032\n",
      "Epoch 85/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4448 - acc: 0.8046\n",
      "Epoch 86/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4448 - acc: 0.8046\n",
      "Epoch 87/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4445 - acc: 0.8046\n",
      "Epoch 88/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4449 - acc: 0.8059\n",
      "Epoch 89/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4446 - acc: 0.8046\n",
      "Epoch 90/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4444 - acc: 0.8046\n",
      "Epoch 91/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4443 - acc: 0.8046\n",
      "Epoch 92/100\n",
      "747/747 [==============================] - 0s 33us/sample - loss: 0.4444 - acc: 0.8046\n",
      "Epoch 93/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4443 - acc: 0.8046\n",
      "Epoch 94/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4443 - acc: 0.8059\n",
      "Epoch 95/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4441 - acc: 0.8059\n",
      "Epoch 96/100\n",
      "747/747 [==============================] - 0s 34us/sample - loss: 0.4442 - acc: 0.8059\n",
      "Epoch 97/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4441 - acc: 0.8046\n",
      "Epoch 98/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4440 - acc: 0.8059\n",
      "Epoch 99/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4441 - acc: 0.8059\n",
      "Epoch 100/100\n",
      "747/747 [==============================] - 0s 34us/sample - loss: 0.4440 - acc: 0.8072\n",
      "83/83 [==============================] - 0s 1ms/sample - loss: 0.4542 - acc: 0.8072\n",
      "Train on 747 samples\n",
      "Epoch 1/100\n",
      "747/747 [==============================] - 0s 275us/sample - loss: 0.6638 - acc: 0.5167\n",
      "Epoch 2/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.6354 - acc: 0.5756\n",
      "Epoch 3/100\n",
      "747/747 [==============================] - 0s 30us/sample - loss: 0.6119 - acc: 0.6265\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747/747 [==============================] - 0s 35us/sample - loss: 0.5918 - acc: 0.6921\n",
      "Epoch 5/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.5744 - acc: 0.7363\n",
      "Epoch 6/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.5599 - acc: 0.7550\n",
      "Epoch 7/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.5473 - acc: 0.7657\n",
      "Epoch 8/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.5362 - acc: 0.7738\n",
      "Epoch 9/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.5274 - acc: 0.7831\n",
      "Epoch 10/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.5193 - acc: 0.7871\n",
      "Epoch 11/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.5127 - acc: 0.7925\n",
      "Epoch 12/100\n",
      "747/747 [==============================] - 0s 64us/sample - loss: 0.5069 - acc: 0.7965\n",
      "Epoch 13/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.5019 - acc: 0.7938\n",
      "Epoch 14/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4977 - acc: 0.7952\n",
      "Epoch 15/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4938 - acc: 0.7938\n",
      "Epoch 16/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4906 - acc: 0.8005\n",
      "Epoch 17/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4879 - acc: 0.8005\n",
      "Epoch 18/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4851 - acc: 0.8072\n",
      "Epoch 19/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4834 - acc: 0.8059\n",
      "Epoch 20/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4816 - acc: 0.8059\n",
      "Epoch 21/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4800 - acc: 0.8072\n",
      "Epoch 22/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4785 - acc: 0.8072\n",
      "Epoch 23/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4772 - acc: 0.8086\n",
      "Epoch 24/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4763 - acc: 0.8072\n",
      "Epoch 25/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4750 - acc: 0.8046\n",
      "Epoch 26/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4744 - acc: 0.8032\n",
      "Epoch 27/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4734 - acc: 0.8032\n",
      "Epoch 28/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4725 - acc: 0.8032\n",
      "Epoch 29/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4717 - acc: 0.8032\n",
      "Epoch 30/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4711 - acc: 0.8046\n",
      "Epoch 31/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4706 - acc: 0.8046\n",
      "Epoch 32/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4700 - acc: 0.8059\n",
      "Epoch 33/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4692 - acc: 0.8099\n",
      "Epoch 34/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4685 - acc: 0.8086\n",
      "Epoch 35/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4679 - acc: 0.8072\n",
      "Epoch 36/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4673 - acc: 0.8059\n",
      "Epoch 37/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4667 - acc: 0.8046\n",
      "Epoch 38/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4661 - acc: 0.8046\n",
      "Epoch 39/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4655 - acc: 0.8059\n",
      "Epoch 40/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4650 - acc: 0.8059\n",
      "Epoch 41/100\n",
      "747/747 [==============================] - 0s 54us/sample - loss: 0.4644 - acc: 0.8059\n",
      "Epoch 42/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4641 - acc: 0.8059\n",
      "Epoch 43/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4635 - acc: 0.8059\n",
      "Epoch 44/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4629 - acc: 0.8059\n",
      "Epoch 45/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4625 - acc: 0.8059\n",
      "Epoch 46/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4616 - acc: 0.8059\n",
      "Epoch 47/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4615 - acc: 0.8032\n",
      "Epoch 48/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4610 - acc: 0.8059\n",
      "Epoch 49/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4606 - acc: 0.8046\n",
      "Epoch 50/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4601 - acc: 0.8046\n",
      "Epoch 51/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4599 - acc: 0.8046\n",
      "Epoch 52/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4594 - acc: 0.8046\n",
      "Epoch 53/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4591 - acc: 0.8046\n",
      "Epoch 54/100\n",
      "747/747 [==============================] - 0s 102us/sample - loss: 0.4586 - acc: 0.8046\n",
      "Epoch 55/100\n",
      "747/747 [==============================] - 0s 52us/sample - loss: 0.4583 - acc: 0.8046\n",
      "Epoch 56/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4580 - acc: 0.8046\n",
      "Epoch 57/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4578 - acc: 0.8046\n",
      "Epoch 58/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4575 - acc: 0.8046\n",
      "Epoch 59/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4571 - acc: 0.8086\n",
      "Epoch 60/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4569 - acc: 0.8086\n",
      "Epoch 61/100\n",
      "747/747 [==============================] - 0s 53us/sample - loss: 0.4567 - acc: 0.8086\n",
      "Epoch 62/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.4563 - acc: 0.8086\n",
      "Epoch 63/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4562 - acc: 0.8086\n",
      "Epoch 64/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4560 - acc: 0.8086\n",
      "Epoch 65/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4558 - acc: 0.8099\n",
      "Epoch 66/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4556 - acc: 0.8099\n",
      "Epoch 67/100\n",
      "747/747 [==============================] - 0s 64us/sample - loss: 0.4555 - acc: 0.8099\n",
      "Epoch 68/100\n",
      "747/747 [==============================] - 0s 62us/sample - loss: 0.4552 - acc: 0.8099\n",
      "Epoch 69/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4550 - acc: 0.8099\n",
      "Epoch 70/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4550 - acc: 0.8086\n",
      "Epoch 71/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4551 - acc: 0.8099\n",
      "Epoch 72/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4545 - acc: 0.8099\n",
      "Epoch 73/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4545 - acc: 0.8099\n",
      "Epoch 74/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4546 - acc: 0.8099\n",
      "Epoch 75/100\n",
      "747/747 [==============================] - 0s 30us/sample - loss: 0.4541 - acc: 0.8099\n",
      "Epoch 76/100\n",
      "747/747 [==============================] - 0s 31us/sample - loss: 0.4539 - acc: 0.8099\n",
      "Epoch 77/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4538 - acc: 0.8099\n",
      "Epoch 78/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4537 - acc: 0.8099\n",
      "Epoch 79/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4536 - acc: 0.8099\n",
      "Epoch 80/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4536 - acc: 0.8099\n",
      "Epoch 81/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4534 - acc: 0.8099\n",
      "Epoch 82/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4533 - acc: 0.8099\n",
      "Epoch 83/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4534 - acc: 0.8099\n",
      "Epoch 84/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4531 - acc: 0.8099\n",
      "Epoch 85/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4532 - acc: 0.8112\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4531 - acc: 0.8099\n",
      "Epoch 87/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4529 - acc: 0.8112\n",
      "Epoch 88/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.4530 - acc: 0.8112\n",
      "Epoch 89/100\n",
      "747/747 [==============================] - 0s 53us/sample - loss: 0.4530 - acc: 0.8126\n",
      "Epoch 90/100\n",
      "747/747 [==============================] - 0s 54us/sample - loss: 0.4527 - acc: 0.8126\n",
      "Epoch 91/100\n",
      "747/747 [==============================] - 0s 53us/sample - loss: 0.4527 - acc: 0.8126\n",
      "Epoch 92/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4524 - acc: 0.8126\n",
      "Epoch 93/100\n",
      "747/747 [==============================] - 0s 54us/sample - loss: 0.4523 - acc: 0.8126\n",
      "Epoch 94/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4522 - acc: 0.8126\n",
      "Epoch 95/100\n",
      "747/747 [==============================] - 0s 59us/sample - loss: 0.4521 - acc: 0.8126\n",
      "Epoch 96/100\n",
      "747/747 [==============================] - 0s 73us/sample - loss: 0.4520 - acc: 0.8126\n",
      "Epoch 97/100\n",
      "747/747 [==============================] - 0s 52us/sample - loss: 0.4519 - acc: 0.8126\n",
      "Epoch 98/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4518 - acc: 0.8126\n",
      "Epoch 99/100\n",
      "747/747 [==============================] - 0s 53us/sample - loss: 0.4516 - acc: 0.8126\n",
      "Epoch 100/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4517 - acc: 0.8126\n",
      "83/83 [==============================] - 0s 1ms/sample - loss: 0.3599 - acc: 0.8313\n",
      "Train on 747 samples\n",
      "Epoch 1/100\n",
      "747/747 [==============================] - 0s 249us/sample - loss: 0.8796 - acc: 0.4016\n",
      "Epoch 2/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.8266 - acc: 0.4150\n",
      "Epoch 3/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.7835 - acc: 0.4110\n",
      "Epoch 4/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.7478 - acc: 0.4230\n",
      "Epoch 5/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.7184 - acc: 0.4418\n",
      "Epoch 6/100\n",
      "747/747 [==============================] - 0s 53us/sample - loss: 0.6921 - acc: 0.5341\n",
      "Epoch 7/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.6683 - acc: 0.6399\n",
      "Epoch 8/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.6471 - acc: 0.6975\n",
      "Epoch 9/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.6286 - acc: 0.7122\n",
      "Epoch 10/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.6122 - acc: 0.7229\n",
      "Epoch 11/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.5966 - acc: 0.7309\n",
      "Epoch 12/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.5826 - acc: 0.7470\n",
      "Epoch 13/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.5695 - acc: 0.7537\n",
      "Epoch 14/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.5570 - acc: 0.7671\n",
      "Epoch 15/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.5457 - acc: 0.7697\n",
      "Epoch 16/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.5350 - acc: 0.7738\n",
      "Epoch 17/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.5253 - acc: 0.7778\n",
      "Epoch 18/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.5163 - acc: 0.7818\n",
      "Epoch 19/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.5077 - acc: 0.7845\n",
      "Epoch 20/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.5000 - acc: 0.7898\n",
      "Epoch 21/100\n",
      "747/747 [==============================] - 0s 52us/sample - loss: 0.4931 - acc: 0.7912\n",
      "Epoch 22/100\n",
      "747/747 [==============================] - 0s 58us/sample - loss: 0.4868 - acc: 0.7912\n",
      "Epoch 23/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4813 - acc: 0.7992\n",
      "Epoch 24/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4763 - acc: 0.8019\n",
      "Epoch 25/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4722 - acc: 0.8019\n",
      "Epoch 26/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4690 - acc: 0.8005\n",
      "Epoch 27/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4659 - acc: 0.8019\n",
      "Epoch 28/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4633 - acc: 0.8059\n",
      "Epoch 29/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4611 - acc: 0.8046\n",
      "Epoch 30/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4588 - acc: 0.8046\n",
      "Epoch 31/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4570 - acc: 0.8046\n",
      "Epoch 32/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4554 - acc: 0.8046\n",
      "Epoch 33/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.4541 - acc: 0.8059\n",
      "Epoch 34/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4530 - acc: 0.8099\n",
      "Epoch 35/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4517 - acc: 0.8099\n",
      "Epoch 36/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4505 - acc: 0.8099\n",
      "Epoch 37/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4496 - acc: 0.8099\n",
      "Epoch 38/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4487 - acc: 0.8099\n",
      "Epoch 39/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4479 - acc: 0.8099\n",
      "Epoch 40/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4473 - acc: 0.8099\n",
      "Epoch 41/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4464 - acc: 0.8126\n",
      "Epoch 42/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4457 - acc: 0.8126\n",
      "Epoch 43/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4452 - acc: 0.8126\n",
      "Epoch 44/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4448 - acc: 0.8126\n",
      "Epoch 45/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4442 - acc: 0.8126\n",
      "Epoch 46/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4439 - acc: 0.8126\n",
      "Epoch 47/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.4434 - acc: 0.8126\n",
      "Epoch 48/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4429 - acc: 0.8139\n",
      "Epoch 49/100\n",
      "747/747 [==============================] - 0s 58us/sample - loss: 0.4426 - acc: 0.8139\n",
      "Epoch 50/100\n",
      "747/747 [==============================] - 0s 57us/sample - loss: 0.4421 - acc: 0.8139\n",
      "Epoch 51/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4417 - acc: 0.8126\n",
      "Epoch 52/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4414 - acc: 0.8139\n",
      "Epoch 53/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4412 - acc: 0.8139\n",
      "Epoch 54/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4409 - acc: 0.8139\n",
      "Epoch 55/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4406 - acc: 0.8112\n",
      "Epoch 56/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4403 - acc: 0.8099\n",
      "Epoch 57/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4400 - acc: 0.8112\n",
      "Epoch 58/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4397 - acc: 0.8099\n",
      "Epoch 59/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4396 - acc: 0.8099\n",
      "Epoch 60/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4394 - acc: 0.8112\n",
      "Epoch 61/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4391 - acc: 0.8126\n",
      "Epoch 62/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4389 - acc: 0.8126\n",
      "Epoch 63/100\n",
      "747/747 [==============================] - 0s 53us/sample - loss: 0.4386 - acc: 0.8126\n",
      "Epoch 64/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.4384 - acc: 0.8112\n",
      "Epoch 65/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4382 - acc: 0.8126\n",
      "Epoch 66/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.4381 - acc: 0.8112\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4379 - acc: 0.8099\n",
      "Epoch 68/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4377 - acc: 0.8112\n",
      "Epoch 69/100\n",
      "747/747 [==============================] - 0s 127us/sample - loss: 0.4376 - acc: 0.8112\n",
      "Epoch 70/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4374 - acc: 0.8112\n",
      "Epoch 71/100\n",
      "747/747 [==============================] - 0s 54us/sample - loss: 0.4373 - acc: 0.8112\n",
      "Epoch 72/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4373 - acc: 0.8112\n",
      "Epoch 73/100\n",
      "747/747 [==============================] - 0s 65us/sample - loss: 0.4369 - acc: 0.8126\n",
      "Epoch 74/100\n",
      "747/747 [==============================] - 0s 65us/sample - loss: 0.4369 - acc: 0.8139\n",
      "Epoch 75/100\n",
      "747/747 [==============================] - 0s 52us/sample - loss: 0.4368 - acc: 0.8153\n",
      "Epoch 76/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4365 - acc: 0.8166\n",
      "Epoch 77/100\n",
      "747/747 [==============================] - 0s 53us/sample - loss: 0.4365 - acc: 0.8166\n",
      "Epoch 78/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.4364 - acc: 0.8166\n",
      "Epoch 79/100\n",
      "747/747 [==============================] - 0s 52us/sample - loss: 0.4362 - acc: 0.8166\n",
      "Epoch 80/100\n",
      "747/747 [==============================] - 0s 54us/sample - loss: 0.4363 - acc: 0.8179\n",
      "Epoch 81/100\n",
      "747/747 [==============================] - 0s 52us/sample - loss: 0.4362 - acc: 0.8193\n",
      "Epoch 82/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4359 - acc: 0.8193\n",
      "Epoch 83/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4360 - acc: 0.8179\n",
      "Epoch 84/100\n",
      "747/747 [==============================] - 0s 53us/sample - loss: 0.4359 - acc: 0.8206\n",
      "Epoch 85/100\n",
      "747/747 [==============================] - 0s 52us/sample - loss: 0.4358 - acc: 0.8206\n",
      "Epoch 86/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4358 - acc: 0.8206\n",
      "Epoch 87/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4356 - acc: 0.8206\n",
      "Epoch 88/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4355 - acc: 0.8206\n",
      "Epoch 89/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4356 - acc: 0.8220\n",
      "Epoch 90/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4353 - acc: 0.8220\n",
      "Epoch 91/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.4352 - acc: 0.8220\n",
      "Epoch 92/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4353 - acc: 0.8220\n",
      "Epoch 93/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4352 - acc: 0.8206\n",
      "Epoch 94/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4352 - acc: 0.8206\n",
      "Epoch 95/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.4351 - acc: 0.8193\n",
      "Epoch 96/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4349 - acc: 0.8206\n",
      "Epoch 97/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.4349 - acc: 0.8206\n",
      "Epoch 98/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4350 - acc: 0.8206\n",
      "Epoch 99/100\n",
      "747/747 [==============================] - 0s 64us/sample - loss: 0.4348 - acc: 0.8179\n",
      "Epoch 100/100\n",
      "747/747 [==============================] - 0s 52us/sample - loss: 0.4347 - acc: 0.8193\n",
      "83/83 [==============================] - 0s 1ms/sample - loss: 0.5207 - acc: 0.7470\n",
      "Train on 747 samples\n",
      "Epoch 1/100\n",
      "747/747 [==============================] - 0s 269us/sample - loss: 0.9045 - acc: 0.2383\n",
      "Epoch 2/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.8480 - acc: 0.2369\n",
      "Epoch 3/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.8015 - acc: 0.2503\n",
      "Epoch 4/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.7630 - acc: 0.3173\n",
      "Epoch 5/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.7308 - acc: 0.3775\n",
      "Epoch 6/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.7039 - acc: 0.4257\n",
      "Epoch 7/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.6803 - acc: 0.4873\n",
      "Epoch 8/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.6607 - acc: 0.5368\n",
      "Epoch 9/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.6427 - acc: 0.5716\n",
      "Epoch 10/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.6268 - acc: 0.6037\n",
      "Epoch 11/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.6126 - acc: 0.6345\n",
      "Epoch 12/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.5995 - acc: 0.6653\n",
      "Epoch 13/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.5874 - acc: 0.6787\n",
      "Epoch 14/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.5758 - acc: 0.7055\n",
      "Epoch 15/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.5643 - acc: 0.7242\n",
      "Epoch 16/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.5536 - acc: 0.7550\n",
      "Epoch 17/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.5428 - acc: 0.7577\n",
      "Epoch 18/100\n",
      "747/747 [==============================] - 0s 52us/sample - loss: 0.5325 - acc: 0.7590\n",
      "Epoch 19/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.5227 - acc: 0.7644\n",
      "Epoch 20/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.5135 - acc: 0.7577\n",
      "Epoch 21/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.5045 - acc: 0.7697\n",
      "Epoch 22/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4967 - acc: 0.7738\n",
      "Epoch 23/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4894 - acc: 0.7778\n",
      "Epoch 24/100\n",
      "747/747 [==============================] - 0s 58us/sample - loss: 0.4829 - acc: 0.7805\n",
      "Epoch 25/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4768 - acc: 0.7831\n",
      "Epoch 26/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4718 - acc: 0.7871\n",
      "Epoch 27/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4668 - acc: 0.7831\n",
      "Epoch 28/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4629 - acc: 0.7818\n",
      "Epoch 29/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4595 - acc: 0.7871\n",
      "Epoch 30/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4567 - acc: 0.7885\n",
      "Epoch 31/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4541 - acc: 0.7898\n",
      "Epoch 32/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4522 - acc: 0.7885\n",
      "Epoch 33/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4506 - acc: 0.7871\n",
      "Epoch 34/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4491 - acc: 0.7871\n",
      "Epoch 35/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4479 - acc: 0.7925\n",
      "Epoch 36/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4470 - acc: 0.7938\n",
      "Epoch 37/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4461 - acc: 0.7952\n",
      "Epoch 38/100\n",
      "747/747 [==============================] - 0s 36us/sample - loss: 0.4452 - acc: 0.7952\n",
      "Epoch 39/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4444 - acc: 0.8005\n",
      "Epoch 40/100\n",
      "747/747 [==============================] - 0s 35us/sample - loss: 0.4438 - acc: 0.7992\n",
      "Epoch 41/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4434 - acc: 0.7992\n",
      "Epoch 42/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4428 - acc: 0.8005\n",
      "Epoch 43/100\n",
      "747/747 [==============================] - 0s 36us/sample - loss: 0.4422 - acc: 0.8046\n",
      "Epoch 44/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4418 - acc: 0.8046\n",
      "Epoch 45/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4414 - acc: 0.8059\n",
      "Epoch 46/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4409 - acc: 0.8072\n",
      "Epoch 47/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4405 - acc: 0.8086\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4401 - acc: 0.8086\n",
      "Epoch 49/100\n",
      "747/747 [==============================] - 0s 36us/sample - loss: 0.4395 - acc: 0.8086\n",
      "Epoch 50/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4391 - acc: 0.8086\n",
      "Epoch 51/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4387 - acc: 0.8086\n",
      "Epoch 52/100\n",
      "747/747 [==============================] - 0s 57us/sample - loss: 0.4382 - acc: 0.8072\n",
      "Epoch 53/100\n",
      "747/747 [==============================] - 0s 63us/sample - loss: 0.4378 - acc: 0.8072\n",
      "Epoch 54/100\n",
      "747/747 [==============================] - 0s 66us/sample - loss: 0.4375 - acc: 0.8072\n",
      "Epoch 55/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4371 - acc: 0.8059\n",
      "Epoch 56/100\n",
      "747/747 [==============================] - 0s 56us/sample - loss: 0.4367 - acc: 0.8059\n",
      "Epoch 57/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.4362 - acc: 0.8059\n",
      "Epoch 58/100\n",
      "747/747 [==============================] - 0s 55us/sample - loss: 0.4360 - acc: 0.8059\n",
      "Epoch 59/100\n",
      "747/747 [==============================] - 0s 53us/sample - loss: 0.4356 - acc: 0.8059\n",
      "Epoch 60/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4354 - acc: 0.8059\n",
      "Epoch 61/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4352 - acc: 0.8059\n",
      "Epoch 62/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4349 - acc: 0.8072\n",
      "Epoch 63/100\n",
      "747/747 [==============================] - 0s 55us/sample - loss: 0.4348 - acc: 0.8072\n",
      "Epoch 64/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4345 - acc: 0.8072\n",
      "Epoch 65/100\n",
      "747/747 [==============================] - 0s 111us/sample - loss: 0.4344 - acc: 0.8086\n",
      "Epoch 66/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4343 - acc: 0.8086\n",
      "Epoch 67/100\n",
      "747/747 [==============================] - 0s 62us/sample - loss: 0.4339 - acc: 0.8086\n",
      "Epoch 68/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4339 - acc: 0.8099\n",
      "Epoch 69/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4337 - acc: 0.8099\n",
      "Epoch 70/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4336 - acc: 0.8099\n",
      "Epoch 71/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4336 - acc: 0.8099\n",
      "Epoch 72/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4335 - acc: 0.8126\n",
      "Epoch 73/100\n",
      "747/747 [==============================] - ETA: 0s - loss: 0.4420 - acc: 0.843 - 0s 42us/sample - loss: 0.4334 - acc: 0.8126\n",
      "Epoch 74/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4333 - acc: 0.8126\n",
      "Epoch 75/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4332 - acc: 0.8139\n",
      "Epoch 76/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4332 - acc: 0.8139\n",
      "Epoch 77/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4332 - acc: 0.8166\n",
      "Epoch 78/100\n",
      "747/747 [==============================] - 0s 64us/sample - loss: 0.4331 - acc: 0.8153\n",
      "Epoch 79/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4329 - acc: 0.8153\n",
      "Epoch 80/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4329 - acc: 0.8166\n",
      "Epoch 81/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4327 - acc: 0.8166\n",
      "Epoch 82/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4326 - acc: 0.8139\n",
      "Epoch 83/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4326 - acc: 0.8153\n",
      "Epoch 84/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4325 - acc: 0.8153\n",
      "Epoch 85/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4324 - acc: 0.8139\n",
      "Epoch 86/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4323 - acc: 0.8139\n",
      "Epoch 87/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4323 - acc: 0.8139\n",
      "Epoch 88/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4322 - acc: 0.8139\n",
      "Epoch 89/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4322 - acc: 0.8139\n",
      "Epoch 90/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4321 - acc: 0.8139\n",
      "Epoch 91/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4319 - acc: 0.8139\n",
      "Epoch 92/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4320 - acc: 0.8139\n",
      "Epoch 93/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4320 - acc: 0.8153\n",
      "Epoch 94/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4317 - acc: 0.8139\n",
      "Epoch 95/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4318 - acc: 0.8139\n",
      "Epoch 96/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4316 - acc: 0.8139\n",
      "Epoch 97/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4315 - acc: 0.8153\n",
      "Epoch 98/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4316 - acc: 0.8153\n",
      "Epoch 99/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4314 - acc: 0.8153\n",
      "Epoch 100/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4314 - acc: 0.8139\n",
      "83/83 [==============================] - 0s 2ms/sample - loss: 0.5409 - acc: 0.7229\n",
      "Train on 747 samples\n",
      "Epoch 1/100\n",
      "747/747 [==============================] - 0s 359us/sample - loss: 0.7168 - acc: 0.4953\n",
      "Epoch 2/100\n",
      "747/747 [==============================] - 0s 59us/sample - loss: 0.6961 - acc: 0.5248\n",
      "Epoch 3/100\n",
      "747/747 [==============================] - 0s 58us/sample - loss: 0.6757 - acc: 0.5823\n",
      "Epoch 4/100\n",
      "747/747 [==============================] - 0s 57us/sample - loss: 0.6563 - acc: 0.6372\n",
      "Epoch 5/100\n",
      "747/747 [==============================] - 0s 54us/sample - loss: 0.6381 - acc: 0.6988\n",
      "Epoch 6/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.6205 - acc: 0.7095\n",
      "Epoch 7/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.6042 - acc: 0.7108\n",
      "Epoch 8/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.5886 - acc: 0.7149\n",
      "Epoch 9/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.5736 - acc: 0.7162\n",
      "Epoch 10/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.5606 - acc: 0.7202\n",
      "Epoch 11/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.5484 - acc: 0.7456\n",
      "Epoch 12/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.5377 - acc: 0.7631\n",
      "Epoch 13/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.5284 - acc: 0.7805\n",
      "Epoch 14/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.5202 - acc: 0.7831\n",
      "Epoch 15/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.5131 - acc: 0.7831\n",
      "Epoch 16/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.5074 - acc: 0.7831\n",
      "Epoch 17/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.5018 - acc: 0.7831\n",
      "Epoch 18/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4974 - acc: 0.7831\n",
      "Epoch 19/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4933 - acc: 0.7818\n",
      "Epoch 20/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4895 - acc: 0.7831\n",
      "Epoch 21/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4864 - acc: 0.7845\n",
      "Epoch 22/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4839 - acc: 0.7845\n",
      "Epoch 23/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4814 - acc: 0.7885\n",
      "Epoch 24/100\n",
      "747/747 [==============================] - ETA: 0s - loss: 0.4761 - acc: 0.791 - 0s 83us/sample - loss: 0.4794 - acc: 0.7898\n",
      "Epoch 25/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4775 - acc: 0.7898\n",
      "Epoch 26/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4758 - acc: 0.7885\n",
      "Epoch 27/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4743 - acc: 0.7912\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4727 - acc: 0.7925\n",
      "Epoch 29/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4712 - acc: 0.7912\n",
      "Epoch 30/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4699 - acc: 0.7898\n",
      "Epoch 31/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.4691 - acc: 0.7898\n",
      "Epoch 32/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4676 - acc: 0.7912\n",
      "Epoch 33/100\n",
      "747/747 [==============================] - 0s 57us/sample - loss: 0.4666 - acc: 0.7898\n",
      "Epoch 34/100\n",
      "747/747 [==============================] - 0s 53us/sample - loss: 0.4657 - acc: 0.7885\n",
      "Epoch 35/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4647 - acc: 0.7885\n",
      "Epoch 36/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.4640 - acc: 0.7898\n",
      "Epoch 37/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4632 - acc: 0.7898\n",
      "Epoch 38/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4624 - acc: 0.7898\n",
      "Epoch 39/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4619 - acc: 0.7885\n",
      "Epoch 40/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4613 - acc: 0.7912\n",
      "Epoch 41/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4608 - acc: 0.7952\n",
      "Epoch 42/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4601 - acc: 0.7938\n",
      "Epoch 43/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4594 - acc: 0.7925\n",
      "Epoch 44/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4590 - acc: 0.7925\n",
      "Epoch 45/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4585 - acc: 0.7912\n",
      "Epoch 46/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.4582 - acc: 0.7925\n",
      "Epoch 47/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4576 - acc: 0.7912\n",
      "Epoch 48/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4573 - acc: 0.7925\n",
      "Epoch 49/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4568 - acc: 0.7925\n",
      "Epoch 50/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4566 - acc: 0.7925\n",
      "Epoch 51/100\n",
      "747/747 [==============================] - 0s 60us/sample - loss: 0.4562 - acc: 0.7965\n",
      "Epoch 52/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4559 - acc: 0.7952\n",
      "Epoch 53/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4556 - acc: 0.7952\n",
      "Epoch 54/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4553 - acc: 0.7992\n",
      "Epoch 55/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4552 - acc: 0.8005\n",
      "Epoch 56/100\n",
      "747/747 [==============================] - 0s 55us/sample - loss: 0.4549 - acc: 0.8019\n",
      "Epoch 57/100\n",
      "747/747 [==============================] - 0s 53us/sample - loss: 0.4545 - acc: 0.8032\n",
      "Epoch 58/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4545 - acc: 0.8032\n",
      "Epoch 59/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4544 - acc: 0.8032\n",
      "Epoch 60/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4540 - acc: 0.8019\n",
      "Epoch 61/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4537 - acc: 0.8019\n",
      "Epoch 62/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4536 - acc: 0.8032\n",
      "Epoch 63/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4534 - acc: 0.8046\n",
      "Epoch 64/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4531 - acc: 0.8072\n",
      "Epoch 65/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4531 - acc: 0.8072\n",
      "Epoch 66/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4530 - acc: 0.8072\n",
      "Epoch 67/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4528 - acc: 0.8112\n",
      "Epoch 68/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4527 - acc: 0.8112\n",
      "Epoch 69/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4524 - acc: 0.8112\n",
      "Epoch 70/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4523 - acc: 0.8112\n",
      "Epoch 71/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4521 - acc: 0.8112\n",
      "Epoch 72/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4521 - acc: 0.8112\n",
      "Epoch 73/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4519 - acc: 0.8112\n",
      "Epoch 74/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4519 - acc: 0.8099\n",
      "Epoch 75/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4517 - acc: 0.8086\n",
      "Epoch 76/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4516 - acc: 0.8086\n",
      "Epoch 77/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4515 - acc: 0.8086\n",
      "Epoch 78/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4513 - acc: 0.8086\n",
      "Epoch 79/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4514 - acc: 0.8086\n",
      "Epoch 80/100\n",
      "747/747 [==============================] - 0s 54us/sample - loss: 0.4513 - acc: 0.8126\n",
      "Epoch 81/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4512 - acc: 0.8139\n",
      "Epoch 82/100\n",
      "747/747 [==============================] - 0s 36us/sample - loss: 0.4513 - acc: 0.8099\n",
      "Epoch 83/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4512 - acc: 0.8126\n",
      "Epoch 84/100\n",
      "747/747 [==============================] - 0s 32us/sample - loss: 0.4512 - acc: 0.8139\n",
      "Epoch 85/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4511 - acc: 0.8139\n",
      "Epoch 86/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4510 - acc: 0.8139\n",
      "Epoch 87/100\n",
      "747/747 [==============================] - 0s 36us/sample - loss: 0.4511 - acc: 0.8139\n",
      "Epoch 88/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4509 - acc: 0.8139\n",
      "Epoch 89/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4508 - acc: 0.8139\n",
      "Epoch 90/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4508 - acc: 0.8153\n",
      "Epoch 91/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4506 - acc: 0.8139\n",
      "Epoch 92/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4505 - acc: 0.8153\n",
      "Epoch 93/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4505 - acc: 0.8153\n",
      "Epoch 94/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4505 - acc: 0.8139\n",
      "Epoch 95/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4507 - acc: 0.8153\n",
      "Epoch 96/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4501 - acc: 0.8153\n",
      "Epoch 97/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4501 - acc: 0.8153\n",
      "Epoch 98/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4500 - acc: 0.8166\n",
      "Epoch 99/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4499 - acc: 0.8153\n",
      "Epoch 100/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4498 - acc: 0.8153\n",
      "83/83 [==============================] - 0s 1ms/sample - loss: 0.3952 - acc: 0.8554\n",
      "Train on 747 samples\n",
      "Epoch 1/100\n",
      "747/747 [==============================] - 0s 333us/sample - loss: 0.9344 - acc: 0.4016\n",
      "Epoch 2/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.8644 - acc: 0.4605\n",
      "Epoch 3/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.8058 - acc: 0.4726\n",
      "Epoch 4/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.7581 - acc: 0.4926\n",
      "Epoch 5/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.7193 - acc: 0.5100\n",
      "Epoch 6/100\n",
      "747/747 [==============================] - 0s 52us/sample - loss: 0.6865 - acc: 0.5448\n",
      "Epoch 7/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.6601 - acc: 0.5489\n",
      "Epoch 8/100\n",
      "747/747 [==============================] - 0s 52us/sample - loss: 0.6377 - acc: 0.5863\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747/747 [==============================] - 0s 45us/sample - loss: 0.6195 - acc: 0.6238\n",
      "Epoch 10/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.6040 - acc: 0.6452\n",
      "Epoch 11/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.5912 - acc: 0.6774\n",
      "Epoch 12/100\n",
      "747/747 [==============================] - 0s 118us/sample - loss: 0.5795 - acc: 0.6894\n",
      "Epoch 13/100\n",
      "747/747 [==============================] - 0s 70us/sample - loss: 0.5702 - acc: 0.6934\n",
      "Epoch 14/100\n",
      "747/747 [==============================] - 0s 55us/sample - loss: 0.5620 - acc: 0.6988\n",
      "Epoch 15/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.5552 - acc: 0.7149\n",
      "Epoch 16/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.5489 - acc: 0.7282\n",
      "Epoch 17/100\n",
      "747/747 [==============================] - 0s 55us/sample - loss: 0.5435 - acc: 0.7336\n",
      "Epoch 18/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.5387 - acc: 0.7403\n",
      "Epoch 19/100\n",
      "747/747 [==============================] - 0s 54us/sample - loss: 0.5342 - acc: 0.7510\n",
      "Epoch 20/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.5302 - acc: 0.7497\n",
      "Epoch 21/100\n",
      "747/747 [==============================] - 0s 80us/sample - loss: 0.5267 - acc: 0.7483\n",
      "Epoch 22/100\n",
      "747/747 [==============================] - 0s 56us/sample - loss: 0.5235 - acc: 0.7497\n",
      "Epoch 23/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.5205 - acc: 0.7523\n",
      "Epoch 24/100\n",
      "747/747 [==============================] - 0s 52us/sample - loss: 0.5177 - acc: 0.7510\n",
      "Epoch 25/100\n",
      "747/747 [==============================] - 0s 54us/sample - loss: 0.5154 - acc: 0.7577\n",
      "Epoch 26/100\n",
      "747/747 [==============================] - 0s 54us/sample - loss: 0.5131 - acc: 0.7657\n",
      "Epoch 27/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.5108 - acc: 0.7697\n",
      "Epoch 28/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.5086 - acc: 0.7697\n",
      "Epoch 29/100\n",
      "747/747 [==============================] - 0s 52us/sample - loss: 0.5069 - acc: 0.7711\n",
      "Epoch 30/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.5052 - acc: 0.7738\n",
      "Epoch 31/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.5036 - acc: 0.7791\n",
      "Epoch 32/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.5023 - acc: 0.7791\n",
      "Epoch 33/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.5008 - acc: 0.7818\n",
      "Epoch 34/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4995 - acc: 0.7805\n",
      "Epoch 35/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4986 - acc: 0.7831\n",
      "Epoch 36/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4973 - acc: 0.7831\n",
      "Epoch 37/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4963 - acc: 0.7845\n",
      "Epoch 38/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4954 - acc: 0.7831\n",
      "Epoch 39/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4945 - acc: 0.7845\n",
      "Epoch 40/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4934 - acc: 0.7845\n",
      "Epoch 41/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4927 - acc: 0.7871\n",
      "Epoch 42/100\n",
      "747/747 [==============================] - 0s 53us/sample - loss: 0.4920 - acc: 0.7831\n",
      "Epoch 43/100\n",
      "747/747 [==============================] - 0s 52us/sample - loss: 0.4913 - acc: 0.7858\n",
      "Epoch 44/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4906 - acc: 0.7871\n",
      "Epoch 45/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4900 - acc: 0.7871\n",
      "Epoch 46/100\n",
      "747/747 [==============================] - 0s 62us/sample - loss: 0.4895 - acc: 0.7871\n",
      "Epoch 47/100\n",
      "747/747 [==============================] - 0s 54us/sample - loss: 0.4888 - acc: 0.7898\n",
      "Epoch 48/100\n",
      "747/747 [==============================] - ETA: 0s - loss: 0.4887 - acc: 0.781 - 0s 54us/sample - loss: 0.4883 - acc: 0.7898\n",
      "Epoch 49/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4876 - acc: 0.7912\n",
      "Epoch 50/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4869 - acc: 0.7898\n",
      "Epoch 51/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4865 - acc: 0.7871\n",
      "Epoch 52/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4860 - acc: 0.7885\n",
      "Epoch 53/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4856 - acc: 0.7885\n",
      "Epoch 54/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4852 - acc: 0.7898\n",
      "Epoch 55/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4846 - acc: 0.7898\n",
      "Epoch 56/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4843 - acc: 0.7898\n",
      "Epoch 57/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4839 - acc: 0.7898\n",
      "Epoch 58/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4835 - acc: 0.7885\n",
      "Epoch 59/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4832 - acc: 0.7871\n",
      "Epoch 60/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4830 - acc: 0.7898\n",
      "Epoch 61/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4825 - acc: 0.7885\n",
      "Epoch 62/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4822 - acc: 0.7898\n",
      "Epoch 63/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4819 - acc: 0.7885\n",
      "Epoch 64/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4815 - acc: 0.7898\n",
      "Epoch 65/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4814 - acc: 0.7898\n",
      "Epoch 66/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4810 - acc: 0.7885\n",
      "Epoch 67/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4807 - acc: 0.7898\n",
      "Epoch 68/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4804 - acc: 0.7898\n",
      "Epoch 69/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4801 - acc: 0.7898\n",
      "Epoch 70/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4798 - acc: 0.7898\n",
      "Epoch 71/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4796 - acc: 0.7912\n",
      "Epoch 72/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4795 - acc: 0.7898\n",
      "Epoch 73/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4791 - acc: 0.7898\n",
      "Epoch 74/100\n",
      "747/747 [==============================] - 0s 83us/sample - loss: 0.4788 - acc: 0.7912\n",
      "Epoch 75/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4785 - acc: 0.7912\n",
      "Epoch 76/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4785 - acc: 0.7912\n",
      "Epoch 77/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4780 - acc: 0.7912\n",
      "Epoch 78/100\n",
      "747/747 [==============================] - 0s 35us/sample - loss: 0.4777 - acc: 0.7912\n",
      "Epoch 79/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4776 - acc: 0.7912\n",
      "Epoch 80/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4773 - acc: 0.7912\n",
      "Epoch 81/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4770 - acc: 0.7912\n",
      "Epoch 82/100\n",
      "747/747 [==============================] - 0s 33us/sample - loss: 0.4769 - acc: 0.7898\n",
      "Epoch 83/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4764 - acc: 0.7898\n",
      "Epoch 84/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4762 - acc: 0.7912\n",
      "Epoch 85/100\n",
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4760 - acc: 0.7925\n",
      "Epoch 86/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4758 - acc: 0.7938\n",
      "Epoch 87/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4755 - acc: 0.7938\n",
      "Epoch 88/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4754 - acc: 0.7925\n",
      "Epoch 89/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4750 - acc: 0.7938\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747/747 [==============================] - 0s 38us/sample - loss: 0.4748 - acc: 0.7938\n",
      "Epoch 91/100\n",
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4747 - acc: 0.7938\n",
      "Epoch 92/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4744 - acc: 0.7925\n",
      "Epoch 93/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4745 - acc: 0.7938\n",
      "Epoch 94/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4741 - acc: 0.7925\n",
      "Epoch 95/100\n",
      "747/747 [==============================] - ETA: 0s - loss: 0.6156 - acc: 0.718 - 0s 46us/sample - loss: 0.4738 - acc: 0.7938\n",
      "Epoch 96/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4737 - acc: 0.7938\n",
      "Epoch 97/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4734 - acc: 0.7952\n",
      "Epoch 98/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.4732 - acc: 0.7952\n",
      "Epoch 99/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4730 - acc: 0.7925\n",
      "Epoch 100/100\n",
      "747/747 [==============================] - 0s 52us/sample - loss: 0.4728 - acc: 0.7925\n",
      "83/83 [==============================] - 0s 1ms/sample - loss: 0.4020 - acc: 0.8675\n",
      "Train on 747 samples\n",
      "Epoch 1/100\n",
      "747/747 [==============================] - 0s 378us/sample - loss: 0.7285 - acc: 0.5422\n",
      "Epoch 2/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.6915 - acc: 0.5730\n",
      "Epoch 3/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.6585 - acc: 0.6854\n",
      "Epoch 4/100\n",
      "747/747 [==============================] - 0s 55us/sample - loss: 0.6297 - acc: 0.7028\n",
      "Epoch 5/100\n",
      "747/747 [==============================] - 0s 64us/sample - loss: 0.6036 - acc: 0.7724\n",
      "Epoch 6/100\n",
      "747/747 [==============================] - 0s 56us/sample - loss: 0.5801 - acc: 0.7898\n",
      "Epoch 7/100\n",
      "747/747 [==============================] - 0s 60us/sample - loss: 0.5582 - acc: 0.7845\n",
      "Epoch 8/100\n",
      "747/747 [==============================] - 0s 61us/sample - loss: 0.5399 - acc: 0.7858\n",
      "Epoch 9/100\n",
      "747/747 [==============================] - 0s 57us/sample - loss: 0.5229 - acc: 0.7938\n",
      "Epoch 10/100\n",
      "747/747 [==============================] - 0s 60us/sample - loss: 0.5084 - acc: 0.7938\n",
      "Epoch 11/100\n",
      "747/747 [==============================] - 0s 60us/sample - loss: 0.4960 - acc: 0.7992\n",
      "Epoch 12/100\n",
      "747/747 [==============================] - 0s 88us/sample - loss: 0.4860 - acc: 0.8005\n",
      "Epoch 13/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4777 - acc: 0.7979\n",
      "Epoch 14/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4718 - acc: 0.7979\n",
      "Epoch 15/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4662 - acc: 0.8032\n",
      "Epoch 16/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4621 - acc: 0.8032\n",
      "Epoch 17/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4584 - acc: 0.8046\n",
      "Epoch 18/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4554 - acc: 0.8019\n",
      "Epoch 19/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4533 - acc: 0.8032\n",
      "Epoch 20/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4511 - acc: 0.8059\n",
      "Epoch 21/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4495 - acc: 0.8032\n",
      "Epoch 22/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4478 - acc: 0.8046\n",
      "Epoch 23/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4466 - acc: 0.8072\n",
      "Epoch 24/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4457 - acc: 0.8072\n",
      "Epoch 25/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4449 - acc: 0.8072\n",
      "Epoch 26/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4443 - acc: 0.8086\n",
      "Epoch 27/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4437 - acc: 0.8072\n",
      "Epoch 28/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4431 - acc: 0.8072\n",
      "Epoch 29/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4429 - acc: 0.8072\n",
      "Epoch 30/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4427 - acc: 0.8046\n",
      "Epoch 31/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4420 - acc: 0.8059\n",
      "Epoch 32/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4418 - acc: 0.8059\n",
      "Epoch 33/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4414 - acc: 0.8059\n",
      "Epoch 34/100\n",
      "747/747 [==============================] - 0s 55us/sample - loss: 0.4410 - acc: 0.8046\n",
      "Epoch 35/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4409 - acc: 0.8072\n",
      "Epoch 36/100\n",
      "747/747 [==============================] - 0s 53us/sample - loss: 0.4406 - acc: 0.8059\n",
      "Epoch 37/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4404 - acc: 0.8046\n",
      "Epoch 38/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4402 - acc: 0.8072\n",
      "Epoch 39/100\n",
      "747/747 [==============================] - 0s 67us/sample - loss: 0.4399 - acc: 0.8099\n",
      "Epoch 40/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4398 - acc: 0.8072\n",
      "Epoch 41/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4396 - acc: 0.8099\n",
      "Epoch 42/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4395 - acc: 0.8153\n",
      "Epoch 43/100\n",
      "747/747 [==============================] - 0s 48us/sample - loss: 0.4395 - acc: 0.8139\n",
      "Epoch 44/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4391 - acc: 0.8139\n",
      "Epoch 45/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4390 - acc: 0.8166\n",
      "Epoch 46/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4388 - acc: 0.8139\n",
      "Epoch 47/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4386 - acc: 0.8126\n",
      "Epoch 48/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4389 - acc: 0.8153\n",
      "Epoch 49/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4384 - acc: 0.8139\n",
      "Epoch 50/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4384 - acc: 0.8126\n",
      "Epoch 51/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.4382 - acc: 0.8166\n",
      "Epoch 52/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4382 - acc: 0.8166\n",
      "Epoch 53/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4380 - acc: 0.8179\n",
      "Epoch 54/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4380 - acc: 0.8166\n",
      "Epoch 55/100\n",
      "747/747 [==============================] - 0s 43us/sample - loss: 0.4377 - acc: 0.8179\n",
      "Epoch 56/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4378 - acc: 0.8166\n",
      "Epoch 57/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4376 - acc: 0.8166\n",
      "Epoch 58/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4376 - acc: 0.8193\n",
      "Epoch 59/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4374 - acc: 0.8193\n",
      "Epoch 60/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4374 - acc: 0.8206\n",
      "Epoch 61/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4373 - acc: 0.8193\n",
      "Epoch 62/100\n",
      "747/747 [==============================] - 0s 44us/sample - loss: 0.4372 - acc: 0.8179\n",
      "Epoch 63/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4374 - acc: 0.8193\n",
      "Epoch 64/100\n",
      "747/747 [==============================] - 0s 42us/sample - loss: 0.4372 - acc: 0.8179\n",
      "Epoch 65/100\n",
      "747/747 [==============================] - 0s 40us/sample - loss: 0.4371 - acc: 0.8179\n",
      "Epoch 66/100\n",
      "747/747 [==============================] - 0s 41us/sample - loss: 0.4370 - acc: 0.8179\n",
      "Epoch 67/100\n",
      "747/747 [==============================] - 0s 76us/sample - loss: 0.4371 - acc: 0.8179\n",
      "Epoch 68/100\n",
      "747/747 [==============================] - 0s 39us/sample - loss: 0.4368 - acc: 0.8179\n",
      "Epoch 69/100\n",
      "747/747 [==============================] - 0s 45us/sample - loss: 0.4369 - acc: 0.8179\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747/747 [==============================] - 0s 37us/sample - loss: 0.4369 - acc: 0.8193\n",
      "Epoch 71/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4366 - acc: 0.8193\n",
      "Epoch 72/100\n",
      "747/747 [==============================] - 0s 36us/sample - loss: 0.4370 - acc: 0.8153\n",
      "Epoch 73/100\n",
      "747/747 [==============================] - 0s 52us/sample - loss: 0.4366 - acc: 0.8179\n",
      "Epoch 74/100\n",
      "747/747 [==============================] - 0s 53us/sample - loss: 0.4365 - acc: 0.8179\n",
      "Epoch 75/100\n",
      "747/747 [==============================] - 0s 56us/sample - loss: 0.4366 - acc: 0.8179\n",
      "Epoch 76/100\n",
      "747/747 [==============================] - 0s 55us/sample - loss: 0.4364 - acc: 0.8179\n",
      "Epoch 77/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.4364 - acc: 0.8179\n",
      "Epoch 78/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4366 - acc: 0.8179\n",
      "Epoch 79/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4362 - acc: 0.8179\n",
      "Epoch 80/100\n",
      "747/747 [==============================] - 0s 53us/sample - loss: 0.4363 - acc: 0.8193\n",
      "Epoch 81/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4361 - acc: 0.8193\n",
      "Epoch 82/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4362 - acc: 0.8193\n",
      "Epoch 83/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4359 - acc: 0.8193\n",
      "Epoch 84/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4359 - acc: 0.8193\n",
      "Epoch 85/100\n",
      "747/747 [==============================] - 0s 103us/sample - loss: 0.4360 - acc: 0.8193\n",
      "Epoch 86/100\n",
      "747/747 [==============================] - 0s 53us/sample - loss: 0.4358 - acc: 0.8193\n",
      "Epoch 87/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.4360 - acc: 0.8193\n",
      "Epoch 88/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4356 - acc: 0.8193\n",
      "Epoch 89/100\n",
      "747/747 [==============================] - 0s 53us/sample - loss: 0.4357 - acc: 0.8179\n",
      "Epoch 90/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4355 - acc: 0.8193\n",
      "Epoch 91/100\n",
      "747/747 [==============================] - 0s 57us/sample - loss: 0.4356 - acc: 0.8179\n",
      "Epoch 92/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4356 - acc: 0.8206\n",
      "Epoch 93/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.4357 - acc: 0.8193\n",
      "Epoch 94/100\n",
      "747/747 [==============================] - 0s 51us/sample - loss: 0.4354 - acc: 0.8166\n",
      "Epoch 95/100\n",
      "747/747 [==============================] - 0s 46us/sample - loss: 0.4355 - acc: 0.8179\n",
      "Epoch 96/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4354 - acc: 0.8166\n",
      "Epoch 97/100\n",
      "747/747 [==============================] - 0s 47us/sample - loss: 0.4353 - acc: 0.8179\n",
      "Epoch 98/100\n",
      "747/747 [==============================] - 0s 50us/sample - loss: 0.4352 - acc: 0.8166\n",
      "Epoch 99/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4353 - acc: 0.8166\n",
      "Epoch 100/100\n",
      "747/747 [==============================] - 0s 49us/sample - loss: 0.4351 - acc: 0.8166\n",
      "83/83 [==============================] - 0s 2ms/sample - loss: 0.5113 - acc: 0.7952\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "clf = KerasClassifier(build_fn=create_model, epochs=100)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76190476 0.76190476 0.88095238 0.81927711 0.8313253  0.71084337\n",
      " 0.79518072 0.82926829 0.8902439  0.79268293]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8073583532737221"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(scores)\n",
    "all_scores.append([\"keras\", scores.mean()])\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst classifier:  ['tree', 0.7421469851531561]\n",
      "Best classifier:  ['linear regression', 0.8073583532737221]\n"
     ]
    }
   ],
   "source": [
    "best_clf = [\"\", 0]\n",
    "worst_clf = ['', 1]\n",
    "\n",
    "for i in all_scores:\n",
    "    if i[1] > best_clf[1]:\n",
    "        best_clf = i\n",
    "    if i[1] < worst_clf[1]:\n",
    "        worst_clf = i\n",
    "        \n",
    "print(\"Worst classifier: \", worst_clf)\n",
    "print(\"Best classifier: \", best_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
